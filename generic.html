<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Blog - Zhipian Zhang</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Blog Post</strong> by Zhipian Zhang</a>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Rio Tinto Mining Survey Scrapper Project — UBC Master of Data Science Team</h1>
									</header>

									<span class="image main"><img src="images/rio-tinto/coverpage.jpg" alt="" /></span>

									<p>Hey there! Welcome to our behind-the-scenes look at the creation of a unique AI project that’s helping Rio Tinto keep their finger on the pulse of the mining industry.</p>
									<p>Imagine this — a system that can wade through the vast ocean of the internet, combing through countless press releases from thousands of resource companies, and finding out the completion status of mining-related geophysics and geochemistry surveys. Sounds like science fiction? Well, it’s the technology for the future that we are developing today. Its aim? To collect all the critical intelligence about planned, in-progress, or recently completed mining-related surveys to help Rio Tinto make savvy investment decisions. Cool, right?</p>
									<p>The heart of the project is its well-defined focus, a product of numerous chats, debates, and brainstorming sessions with our partners. When we kicked off, we had around 20 overlapping mining-related events to pick from — everything from operational details to financial decisions and personnel changes. With so many possibilities, we did our homework and got familiar with the ins and outs of the mining industry, tracing the mineral exploration roadmap from initial prospecting and surveys all the way to discovery and continuous monitoring.</p>
									<p>But the jackpot question was — what event should we prioritize for tracking from a business perspective? After a lot of discussions, we and our partners concluded that the most valuable information to follow would be mining-related geophysics or geochemistry surveys, their completion status, and the survey's begin and end dates.</p>

									<span class="image main"><img src="images/rio-tinto/survey-types.png" alt="" /></span>

									<p>Now, onto the big hurdle: the data we received. Rio Tinto had given us an impressive dataset of around 33,000 press releases, but there was a catch — none of the info about survey type, temporal status, or date was labeled. Yes, you heard it right, a goldmine of information but not a label in sight.</p>
									<p>We took a swing at several unsupervised learning approaches, like topic modeling using Latent Dirichlet Allocation (LDA), and information retrieval using Facebook’s pretrained Contriver model for zero-shot classification. But the results? Well, let’s just say they left something to be desired.</p>
									<p>After a solid chat with our academic advisor, Professor Zhu, we realized that a supervised approach could be a game-changer for our performance levels. But how can you supervise without labels? That’s where GPT, one of the most popular large language models, comes in.</p>
									<p>We designed a workflow that passed the historical dataset through GPT to annotate the data. We started off with a basic prompt to annotate 5000 press releases and used stratified sampling to choose a 130-example test set. We then manually annotated each example and treated them as our ground-truth. By carefully tweaking our prompts and selecting the one with the best score on the test set, we were able to annotate the entire 33K PRs dataset.</p>
									<p>Once we had our labels, it was time to train our models. We leaned heavily on transformer-based models, utilizing both encoders and decoders, since they’re the go-to for classification and information retrieval tasks. We tried a few models, including Distilbert, Bidirectional LSTM, FASText, and DistilRoBERTa. We also experimented with adding extra input features to the model, like the survey type from the first model to improve the performance of the completion status classification model.</p>
									<p>And voila! The project came together like a well-oiled machine. Want to get a glimpse of the bigger picture? Check out the complete flow chart of our project below.</p>

									<span class="image main"><img src="images/rio-tinto/flowchart.png" alt="" /></span>

									<hr class="major" />

									<h2>Data</h2>
									<p>Let us tell you more about the dataset we are working with.First off, we had to create a press release dataset. But we couldn’t just pull it off some random database, we had to scrape it from the news pages of companies in the mining and natural resources industry. Sounds simple, right? Not exactly.</p>
									<p>We started with a list of 1090 companies and their respective news directory URLs in a humble csv file. But here’s the kicker, the actual news articles (or press releases) were scattered around the news directory, waiting to be parsed. For example, below is the news directory of Rio Tinto. So we wrote a script that would first fish out the news links on each company’s news directory page, and then wade through each link, one by one. </p>
									<span class="image main"><img src="images/rio-tinto/news-directory.png" alt="" /></span>
									
									<p>By going through this process, we had a shiny new csv file holding 9872 freshly scraped press releases from 638 companies. On top of the textual content we extracted the metadata for the press releases too. So we have the PR titles and published dates, for when they exist, all neatly arranged in our dataset.</p>
									<p>Some of these press releases were in HTML format, and some in PDF. So, we had to use different scrapers depending on the format. Take a look at our workflow diagram here that shows what this pipeline looks like:</p>
									<span class="image main"><img src="images/rio-tinto/scraping-flowchart.png" alt="" /></span>
									<p>Most of the newly scrapped press releases are published between 2020 to 2024, which are quite recent. The average length of each press release is around 900 words. You can see the distribution of the publish dates and the news’ lengths in the dataset:</p>
									<span class="image main"><img src="images/rio-tinto/publish-date-avg-len-dist.png" alt="" /></span>
									<hr class="major" />

									<h2>Annotating the historical dataset with prompt engineering</h2>
									<p>After we scraped our initial press release dataset, we turned our attention to annotating the historical dataset provided by our friends at Rio Tinto.</p>
									<p>This historical dataset was a massive collection of roughly 33,000 press releases. Well, to be exact, the merged first two paragraphs of each, because based on our observations, they contain the most important information for each press release. But here’s where it gets interesting — we then used the GPT-3.5 Turbo model from OpenAI to annotate each press release with survey type information. “Geochemistry Survey,” “Geophysics Survey,” “Both,” and “Others” were the categories we’re talking about. “Both” category is for when a press release mentioned both geochemistry and geophysics surveys, and “Others” is for the ones that didn’t mention either.</p>
									<p>We didn’t stop there, because GPT was also tasked with determining the completion status of any mentioned survey. The labels were “Planned,” “In-progress,” “Ended,” or “Result-released”.</p>
									<p>And if the press releases mentioned any dates, GPT would extract the specific start and end dates of the surveys. Check out these distribution charts to see how the survey type and the completion status annotations are spread across our dataset:</p>
									<span class="image main"><img src="images/rio-tinto/survey-type-temporal-dist.png" alt="" /></span>
									<p>As an extra step, with the help of the partners from Rio Tinto, we manually annotated 130 examples pulled from the historical dataset. Think of these manual annotations as our gold label, a benchmark to test the accuracy of our GPT labels and model outputs. Since the majority of the PRs fall under the survey type “Others,” a simple random sampling from the historical dataset would not provide us with balanced data to test the results accurately. To address this, we have prompted the GPT again on 5000 samples to obtain their survey type and temporal labels. From these results, we have performed stratified sampling to select 10 examples for each class combination, resulting in a total of 130 samples.</p>
									<p>Below is the best prompt we used for annotating the survey type. You can check our final report for other prompts we are using for each of the classifications and the date extraction tasks.</p>
									<span class="image main"><img src="images/rio-tinto/prompt-engineering-pipeline-and-survey-type-prompt.png" alt="" /></span>

									<p>Our GPT labels for survey type hit an impressive accuracy score of 0.81 on our test set of 130 examples. When classifying the completion status and extracting dates for those examples identified as a survey by the first model, things got a bit trickier. Some examples were wrongly predicted as “Others” and lacked a completion status or dates. If we include these misclassified examples, our accuracy for the completion status model is 0.77. Exclude them, and our accuracy increases up to 0.92! As for the start and end dates, we correctly labeled these for 73% of all geophysics surveys and 67% of geochemistry surveys.</p>
									
									<hr class="major" />
									<h2>Methods</h2>
									<h3>Zero-shot attempts and approaches</h3>
									<p>We tried the following zero-shot methods:</p>
									<ol>
										<li>ZeroShot Two Step Classification(based on Facebook Contriever)</li>
										<li>ZeroShot one step Classification(based on Facebook Contriever)</li>
										<li>ZeroShot one step Classification(based on Sentence Transformers)</li>
										<li>BERTopic modeling</li>
									</ol>
									<p>ZeroShot Two Step Classification (Facebook Contriever): The ZeroShot Two Step Classification approach based on Facebook Contriever did not meet our expectations due to challenges in determining thresholds and linear relevance scoring. These limitations affected the accuracy and performance of the model.</p>
									<p>ZeroShot One Step Classification (Facebook Contriever): The ZeroShot One Step Classification approach based on Facebook Contriever did not yield satisfactory results. The model’s performance fell short of expectations, indicating the need for further improvements and alternative approaches.</p>
									<p>ZeroShot One Step Classification (Sentence Transformers): The ZeroShot One Step Classification approach based on Sentence Transformers showed potential but did not meet our desired level of performance. Although sentence similarity was utilized for classification, the results did not meet expectations, suggesting the need for enhancements and refinements in the model.</p>
									<p>BERTopic Modeling: BERTopic, a topic modeling technique based on the BERT language model, showed promising results in generating meaningful and interpretable topics from text data. However, during hyperparameter tuning, it was observed that reducing the number of topics adversely affected the model’s performance. Further exploration and optimization are required to improve the performance of BERTopic.</p>
									<h3>Methods for Training the Classification Model using Supervised Learning</h3>
									<p>We tried the following supervised learning methods:</p>
									<ol>
										<li>Distilbert base</li>
										<li>Bidirectional LSTM with DistilBERT Base</li>
										<li>FASText</li>
										<li>DistilRoBERTa</li>
									</ol>
									<p>To develop effective classification models, we trained different models like DistilBERT, FastText, and DistilRoBERTa. We followed a systematic process for training these models, including data preprocessing, tokenization, model initialization, and iterative training to improve performance. Below is the flowchart of the process:</p>
									<span class="image main"><img src="images/rio-tinto/model-training-flowchart.png" alt="" /></span>
									<p>After training the models, we evaluated their performance using the testing dataset. We calculated metrics such as accuracy, precision, recall, and F1-score to measure how well the models classified the data. We also generated classification reports and confusion matrices to get a better understanding of their overall performance.</p>
									<h3>Question-Answering Date Extractive model</h3>
									<p>For the extraction of dates, we decided to use question answering models. After experimenting with a wide range of models, we decided to go with the Flan-T5 model. </p>
									<p>To train the Flan-T5 model for date extraction, we uses three inputs which are the survey type, the data type that we want to extract, and the input text containing the actual date. Below is an example showing how we combine those three inputs into a single text using a template.
									<span class="image main"><img src="images/rio-tinto/date-extraction-inputs.png" alt="" /></span>

									<p>Following this system, we extracted the start and end date of the specified survey type. In cases where the survey type was ‘Other’, we skipped it. In cases where the survey type was ‘Both’, we predicted the start and end times for both Geophysical and Geochemical survey.</p>
									<p>Since the model makes predictions in all cases, including the ones where a date is not present, we need to filter out the predictions where there is no date. For this, we first tried using scores to filter out irrelevant predictions. This was not as effective as expected, hence, we used a date parser to detect the presence of a date and standardize it. We also tried to filter out all the entries which were not able to be standardized. By doing this, we did lose some valid predictions, which led to a lower accuracy.</p>
									<p>We finally used a combination of scoring and standardization to filter the results. This resulted in a much better output which consists only of dates. Below are one example of end date extraction:</p>
									<span class="image main"><img src="images/rio-tinto/end-date-extraction-example.png" alt="" /></span>
									
									<hr class="major" />
									<h2>Evaluation & Analysis of the Models</h2>

								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li><a href="generic.html">Generic</a></li>
										<li><a href="elements.html">Elements</a></li>
										<li>
											<span class="opener">Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Etiam Dolore</a></li>
										<li><a href="#">Adipiscing</a></li>
										<li>
											<span class="opener">Another Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Maximus Erat</a></li>
										<li><a href="#">Sapien Mauris</a></li>
										<li><a href="#">Amet Lacinia</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Ante interdum</h2>
									</header>
									<div class="mini-posts">
										<article>
											<a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic08.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic09.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
									</div>
									<ul class="actions">
										<li><a href="#" class="button">More</a></li>
									</ul>
								</section>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">information@untitled.tld</a></li>
										<li class="icon solid fa-phone">(000) 000-0000</li>
										<li class="icon solid fa-home">1234 Somewhere Road #8254<br />
										Nashville, TN 00000-0000</li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>